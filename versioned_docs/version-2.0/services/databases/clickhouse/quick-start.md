---
sidebar_position: 2
title: D√©marrage rapide
---

# D√©ployer ClickHouse en 5 minutes

Ce guide vous accompagne dans le d√©ploiement de votre premi√®re base de donn√©es **ClickHouse** sur Hikube en **quelques minutes**!

---

## Objectif

√Ä la fin de ce guide, vous aurez :  
- Une base de donn√©es **ClickHouse** d√©ploy√©e sur Hikube  
- Une configuration initiale avec **shards** et **r√©plicas** adapt√©e √† vos besoins  
- Un utilisateur et un mot de passe pour vous connecter  
- Un stockage persistant pour conserver vos donn√©es  

---

## Pr√©requis

Avant de commencer, assurez-vous d'avoir :  
- **kubectl** configur√© avec votre kubeconfig Hikube  
- **Droits administrateur** sur votre tenant  
- Un **namespace** disponible pour h√©berger votre base de donn√©es  
- (Optionnel) Un bucket **S3-compatible** si vous souhaitez activer les sauvegardes automatiques  

---

## √âtape 1 : Cr√©ation yaml Clickhouse

### **Pr√©parez le fichier manifest**

Cr√©ez un fichier `clickhouse.yaml` comme ci-dessous: 

```yaml title="clickhouse.yaml"
apiVersion: apps.cozystack.io/v1alpha1
appVersion: 0.13.0
kind: ClickHouse
metadata:
  name: example
spec:
#   backup:
#     cleanupStrategy: --keep-last=3 --keep-daily=3 --keep-within-weekly=1m
#     enabled: false
#     resticPassword: <password>
#     s3AccessKey: <your-access-key>
#     s3Bucket: s3.example.org/clickhouse-backups
#     s3Region: us-east-1
#     s3SecretKey: <your-secret-key>
#     schedule: 0 2 * * *
  clickhouseKeeper:
    enabled: true
    replicas: 3
    resourcesPreset: micro
    size: 1Gi
  logStorageSize: 2Gi
  logTTL: 15
  replicas: 2
  resources:
    cpu: 3000m
    memory: 3Gi
  resourcesPreset: small
  shards: 1
  size: 10Gi
  storageClass: ""
  users:
    user1:
      password: strongpassword
    user2:
        readonly: true
        password: hackme      
```

### **D√©ployez le yaml clickhouse**

```bash
# Appliquer le yaml
kubectl apply -f clickhouse.yaml
```

## √âtape 2 : V√©rification et Tests

Une fois l'application d√©ploy√©, v√©rifier que tout fonctionne :

```bash
# V√©rifier le statut (peut prendre 1-2 minutes)
‚ûú  ~ kubectl get clickhouse
NAME      READY   AGE     VERSION
example   True    4m48s   0.13.0

# V√©rifier si les pods applicatifs sont running
‚ûú  ~ kubectl get po | grep clickhouse
chi-clickhouse-example-clickhouse-0-0-0           1/1     Running     0             3m43s
chi-clickhouse-example-clickhouse-0-1-0           1/1     Running     0             2m28s
chk-clickhouse-example-keeper-cluster1-0-0-0      1/1     Running     0             3m17s
chk-clickhouse-example-keeper-cluster1-0-1-0      1/1     Running     0             2m50s
chk-clickhouse-example-keeper-cluster1-0-2-0      1/1     Running     0             2m28s

# Vous pouvez r√©cup√©rer le username, password de votre BDD
  ~ kubectl get secret clickhouse-example-credentials \
  -n tenant-jeanluc \
  -o jsonpath="{.data}" | jq .

{
  "backup": "dklkWlVOaWFMS2FWYkl2bA==",
  "user1": "c3Ryb25ncGFzc3dvcmQ=",
  "user2": "aGFja21l"
}

# Faire un port-forward du service pour y acc√©der en local, ou modifier le service en tant que LoadBalancer
kubectl port-forward svc/chendpoint-clickhouse-example 9000:9000

# Dans un autre terminal se connecter et v√©rifier la version de clickhouse
‚ûú  ~ clickhouse-client \
  --host 127.0.0.1 \
  --port 9000 \
  --user user1 \
  --password 'strongpassword' \
  --query "SHOW DATABASES; "
INFORMATION_SCHEMA
default
information_schema
system
```

---

## üìã R√©sum√©

Vous avez d√©ploy√© :  

- Une base de donn√©es **ClickHouse** sur votre tenant Hikube  
- Une configuration initiale avec **shards** et **r√©plicas**  
- Un composant **ClickHouse Keeper** pour la coordination du cluster  
- Un stockage persistant attach√© pour vos donn√©es et logs  
- Des utilisateurs avec mots de passe g√©n√©r√©s et stock√©s dans un Secret Kubernetes  
- Un acc√®s √† votre base via `clickhouse-client`
- La possibilit√© de configurer des **sauvegardes S3** automatiques  