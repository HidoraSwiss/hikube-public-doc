---
sidebar_position: 2
title: D√©marrage Rapide - VM GPU
---

# Cr√©er votre premi√®re Machine Virtuelle GPU

Ce guide vous accompagne dans la cr√©ation de votre premi√®re machine virtuelle GPU Hikube en **10 minutes** ! D√©couvrez la puissance d'acc√©l√©ration des GPUs NVIDIA L40S, A100 et H100. üöÄ

---

## üéØ Objectif

√Ä la fin de ce guide, vous aurez :
- Une machine virtuelle avec GPU NVIDIA d√©di√©
- Pilotes NVIDIA et CUDA op√©rationnels
- Acc√®s direct au GPU via passthrough
- Environnement de d√©veloppement IA pr√™t

---

## üìã Pr√©requis

Avant de commencer, assurez-vous d'avoir :
- **kubectl** configur√© avec votre kubeconfig Hikube
- **Droits administrateur** sur votre tenant
- **virtctl** install√© pour l'acc√®s console

---

## üöÄ √âtape 1 : Cr√©er le Disque VM GPU (3 minutes)

### **Pr√©parez le fichier manifest**

Cr√©ez un fichier `vm-gpu-disk.yaml` avec une image Ubuntu optimis√©e pour GPU :

```yaml title="vm-gpu-disk.yaml"
apiVersion: apps.cozystack.io/v1alpha1
kind: VMDisk
metadata:
  name: disk-gpu-example
spec:
  source:
    http:
      url: https://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-amd64.img
  optical: false
  storage: 100Gi
  storageClass: "replicated"
```

### **D√©ployez le disque**

```bash
# Cr√©er le disque VM GPU
kubectl apply -f vm-gpu-disk.yaml

# V√©rifier le statut (peut prendre 2-3 minutes)
kubectl get vmdisk disk-gpu-example -w
```

**R√©sultat attendu :**
```
NAME               STATUS   SIZE    STORAGECLASS   AGE
disk-gpu-example   Ready    100Gi   replicated     120s
```

---

## üéÆ √âtape 2 : Cr√©er la VM avec GPU (5 minutes)

### **Choisissez votre GPU**

Hikube propose 3 types de GPUs professionnels :

| GPU Type | Architecture | M√©moire | Usage Principal |
|----------|-------------|---------|-----------------|
| **L40S** | Ada Lovelace | 48GB | IA g√©n√©rative, rendu |
| **A100** | Ampere | 80GB | Entra√Ænement IA |
| **H100** | Hopper | 80GB | LLM, transformers |

### **Pr√©parez le manifest VM GPU**

Cr√©ez un fichier `vm-gpu-instance.yaml` avec le GPU de votre choix :

```yaml title="vm-gpu-instance.yaml"
apiVersion: apps.cozystack.io/v1alpha1
kind: VirtualMachine
metadata:
  name: vm-gpu-example
spec:
  running: true
  instanceProfile: ubuntu
  instanceType: g1.xlarge  # Type optimis√© GPU
  systemDisk:
    size: 100Gi
    storageClass: replicated
  disks:
    - name: disk-gpu-example
  gpus:
    - name: "nvidia.com/L40S"  # Changez selon votre besoin
      # Options: nvidia.com/L40S, nvidia.com/A100, nvidia.com/H100
  cloudInit: |
    #cloud-config
    users:
      - name: ubuntu
        sudo: ALL=(ALL) NOPASSWD:ALL
        shell: /bin/bash
        ssh_authorized_keys:
          - ssh-rsa AAAAB3NzaC1yc2E... # Votre cl√© SSH publique
    package_update: true
    packages:
      - curl
      - wget
      - git
      - build-essential
    runcmd:
      - curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/3bf863cc.pub | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-developers.gpg
      - echo "deb [arch=amd64,arm64 signed-by=/usr/share/keyrings/nvidia-developers.gpg] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ /" | sudo tee /etc/apt/sources.list.d/nvidia-developers.list
      - sudo apt update
      - sudo apt install -y nvidia-driver-535 cuda-toolkit-12-2
      - sudo systemctl enable nvidia-persistenced
```

### **D√©ployez la VM GPU**

```bash
# Cr√©er la VM GPU
kubectl apply -f vm-gpu-instance.yaml

# V√©rifier le statut (peut prendre 3-5 minutes)
kubectl get vm vm-gpu-example -w
```

**R√©sultat attendu :**
```
NAME             AGE   STATUS    READY
vm-gpu-example   3m    Running   True
```

---

## üîå √âtape 3 : Acc√©der √† votre VM GPU (2 minutes)

### **M√©thodes d'acc√®s**

#### **Option 1 : SSH Direct**
```bash
# SSH via virtctl (avec cl√© personnalis√©e)
virtctl ssh -i ~/.ssh/hikube-vm ubuntu@vm-gpu-example
```

### **Options avec virtctl**
### **Installation de virtctl**

Si vous n'avez pas encore `virtctl` install√© :

```bash
# Installation de virtctl
export VERSION=$(curl https://storage.googleapis.com/kubevirt-prow/release/kubevirt/kubevirt/stable.txt)
wget https://github.com/kubevirt/kubevirt/releases/download/${VERSION}/virtctl-${VERSION}-linux-amd64
chmod +x virtctl
sudo mv virtctl /usr/local/bin/

# V√©rifier l'installation
virtctl version
```

#### **Option 2 : Console S√©rie (toujours disponible)**
```bash
# Acc√®s console directe
virtctl console vm-gpu-example
```

#### **Option 3 : Interface VNC**
```bash
# Acc√®s graphique
virtctl vnc vm-gpu-example
```

---

## ‚úÖ √âtape 4 : Validation GPU (2 minutes)

### **Tests de fonctionnement GPU**

Une fois connect√© √† votre VM, testez l'acc√®s GPU :

```bash
# V√©rification du driver NVIDIA
nvidia-smi

# Information syst√®me
lspci | grep NVIDIA

# Test CUDA (si install√©)
nvcc --version

# Test simple de calcul GPU
nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv
```

### **R√©sultat attendu**
```bash
ubuntu@vm-gpu-example:~$ nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.XX       Driver Version: 535.XX       CUDA Version: 12.2   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA L40S         On   | 00000000:06:00.0 Off |                  Off |
| N/A   30C    P8    25W / 300W |      1MiB / 48000MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
```

### **Installation de frameworks IA (optionnel)**

```bash
# Installation de PyTorch avec support CUDA
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Installation de TensorFlow avec GPU
pip3 install tensorflow[and-cuda]

# Test PyTorch GPU
python3 -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Non d√©tect√©\"}')"
```

### **R√©sultat attendu PyTorch**
```bash
CUDA disponible: True
GPU: NVIDIA L40S
```

---

## üéâ F√©licitations !

Votre VM GPU est maintenant op√©rationnelle ! Vous pouvez :

### **üîÑ Prochaines √©tapes**

**D√©veloppement IA :**
- Installer Jupyter Lab pour le d√©veloppement interactif
- Cloner vos projets depuis GitHub
- T√©l√©charger des datasets depuis Hugging Face

**Calcul Scientifique :**
- Installer GROMACS, OpenFOAM ou autres outils
- Configurer MPI pour calculs distribu√©s
- Optimiser les performances avec cuBLAS

**Rendu et Visualisation :**
- Installer Blender ou applications 3D
- Configurer le streaming distant
- Optimiser l'encoding vid√©o avec NVENC

### **üìñ Ressources Avanc√©es**

- **[Configuration Multi-GPU](./api-reference.md#multi-gpu)** ‚Üí Scaling horizontal
- **[Optimisation Performance](./api-reference.md#performance)** ‚Üí Tuning avanc√©
- **[Monitoring GPU](./api-reference.md#monitoring)** ‚Üí Observabilit√©

:::tip Performance Tip üí°
Pour les workloads de production, utilisez toujours des instances g1.xxlarge ou sup√©rieures avec stockage NVMe local pour les datasets temporaires.
:::

:::warning Important üö®
Les GPUs sont des ressources limit√©es. Pensez √† arr√™ter vos VMs (`kubectl patch vm vm-gpu-example -p '{"spec":{"running":false}}'`) quand vous ne les utilisez pas pour optimiser les co√ªts.
:::

---

**Pr√™t pour plus ?** Consultez la [r√©f√©rence API compl√®te](./api-reference.md) pour explorer toutes les possibilit√©s des VMs GPU Hikube ! üöÄ 