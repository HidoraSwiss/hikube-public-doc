---
sidebar_position: 2
title: D√©marrage rapide
---

# Utiliser les GPU sur Hikube

Ce guide pr√©sente les deux m√©thodes d'utilisation des GPU : avec des machines virtuelles et avec des clusters Kubernetes.

---

## üéØ M√©thodes d'Usage

Hikube propose deux approches pour utiliser les GPU :

1. **GPU avec VM** : Attachment direct d'un GPU √† une machine virtuelle
2. **GPU avec Kubernetes** : Allocation de GPU aux workers pour utilisation par les pods

---

## üñ•Ô∏è M√©thode 1 : GPU avec Machine Virtuelle

### **√âtape 1 : Cr√©er le disque**

```yaml title="vm-disk.yaml"
apiVersion: apps.cozystack.io/v1alpha1
kind: VMDisk
metadata:
  name: ubuntu-gpu-disk
spec:
  source:
    http:
      url: https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img
  optical: false
  storage: 50Gi
  storageClass: "replicated"
```

### **√âtape 2 : Cr√©er la VM avec GPU**

```yaml title="vm-gpu.yaml"
apiVersion: apps.cozystack.io/v1alpha1
kind: VirtualMachine
metadata:
  name: vm-gpu-example
spec:
  running: true
  instanceProfile: ubuntu
  instanceType: u1.xlarge  # 4 vCPU, 16 GB RAM
  gpus:
    - name: "nvidia.com/L40S"
  systemDisk:
    size: 50Gi
    storageClass: replicated
  external: true
  externalMethod: PortList
  externalPorts:
    - 22
  sshKeys:
    - "ssh-rsa AAAAB3NzaC... votre-cl√©-publique"
  cloudInit: |
    #cloud-config
    users:
      - name: ubuntu
        sudo: ALL=(ALL) NOPASSWD:ALL
        shell: /bin/bash
    
    package_update: true
    packages:
      - curl
      - wget
      - build-essential
    
    runcmd:
      # Installation pilotes NVIDIA
      - wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
      - dpkg -i cuda-keyring_1.0-1_all.deb
      - apt-get update
      - apt-get install -y cuda-toolkit nvidia-driver-535
      - nvidia-smi -pm 1
```

### **√âtape 3 : D√©ployer**

```bash
kubectl apply -f vm-disk.yaml
kubectl apply -f vm-gpu.yaml

# V√©rifier l'√©tat
kubectl get virtualmachine vm-gpu-example
```

### **√âtape 4 : Acc√©der et tester**

```bash
# Acc√®s SSH
virtctl ssh ubuntu@vm-gpu-example

# V√©rifier le GPU
nvidia-smi
```

---

## ‚ò∏Ô∏è M√©thode 2 : GPU avec Kubernetes

### **√âtape 1 : Cr√©er un cluster avec workers GPU**

```yaml title="cluster-gpu.yaml"
apiVersion: apps.cozystack.io/v1alpha1
kind: Kubernetes
metadata:
  name: cluster-gpu
spec:
  controlPlane:
    replicas: 1
  
  nodeGroups:
    # Workers GPU
    gpu-nodes:
      minReplicas: 1
      maxReplicas: 3
      instanceType: "u1.xlarge"
      ephemeralStorage: 100Gi
      gpus:
        - name: "nvidia.com/L40S"
    
    # Workers standard (optionnel)
    standard-nodes:
      minReplicas: 1
      maxReplicas: 2
      instanceType: "s1.medium"
      ephemeralStorage: 50Gi
  
  storageClass: "replicated"
```

### **√âtape 2 : D√©ployer le cluster**

```bash
kubectl apply -f cluster-gpu.yaml

# Attendre que le cluster soit pr√™t
kubectl get kubernetes cluster-gpu -w
```

### **√âtape 3 : Configurer l'acc√®s**

```bash
# R√©cup√©rer le kubeconfig
kubectl get secret cluster-gpu-admin-kubeconfig \
  -o go-template='{{ printf "%s\n" (index .data "super-admin.conf" | base64decode) }}' \
  > cluster-gpu-kubeconfig.yaml

# Utiliser le cluster GPU
export KUBECONFIG=cluster-gpu-kubeconfig.yaml
kubectl get nodes
```

### **√âtape 4 : D√©ployer un pod GPU**

```yaml title="pod-gpu.yaml"
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:12.0-runtime-ubuntu20.04
    command: ["sleep", "infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1
      requests:
        nvidia.com/gpu: 1
```

```bash
kubectl apply -f pod-gpu.yaml

# V√©rifier l'allocation GPU
kubectl describe pod gpu-test

# Tester le GPU
kubectl exec -it gpu-test -- nvidia-smi
```

---

## üìã Comparaison Pratique

| **Aspect** | **VM GPU** | **Kubernetes GPU** |
|------------|------------|-------------------|
| **Temps setup** | ~5 minutes | ~10 minutes |
| **Complexit√©** | Simple | Mod√©r√©e |
| **Isolation** | Totale | Partielle |
| **Flexibilit√©** | Limit√©e | √âlev√©e |
| **Scaling** | Manuel | Automatique |

---

## üîß Types de GPU Disponibles

### **Configuration selon l'usage**

```yaml
# Pour inf√©rence/d√©veloppement
gpus:
  - name: "nvidia.com/L40S"  # 48 GB GDDR6

# Pour entra√Ænement ML
gpus:
  - name: "nvidia.com/A100"  # 80 GB HBM2e

# Pour LLM/calcul exascale
gpus:
  - name: "nvidia.com/H100"  # 80 GB HBM3
```

---

## ‚úÖ V√©rifications Post-D√©ploiement

### **VM GPU**
```bash
# V√©rifier le GPU
virtctl ssh ubuntu@vm-gpu-example -- nvidia-smi

# Test CUDA
virtctl ssh ubuntu@vm-gpu-example -- nvcc --version
```

### **Kubernetes GPU**
```bash
# Voir les ressources GPU disponibles
kubectl describe nodes

# V√©rifier l'allocation
kubectl top nodes
```

---

## üöÄ Prochaines √âtapes

### **Pour approfondir VM GPU :**
- [Configuration avanc√©e VM](./api-reference.md)
- [Types d'instances optimis√©es](../compute/api-reference.md)

### **Pour approfondir Kubernetes GPU :**
- [Clusters avec GPU](../kubernetes/api-reference.md)
- [Scaling automatique](../kubernetes/overview.md)

---

## üí° Conseils

- **VM GPU** : Id√©al pour prototypage et applications legacy
- **Kubernetes GPU** : Recommand√© pour workloads de production scalables
- Commencez par **L40S** pour tester avant d'utiliser A100/H100
- Utilisez `replicated` storage class pour la production 